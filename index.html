<p id=“volume”></p>
<div id=“vol_effect”></div>

<script>
function audio_input(){
window.AudioContext = window.AudioContext || window.webkitAudioContext;
var context = new AudioContext();
//AnalyserNodeオブジェクト(音声解析用クラス)のインスタンス化
var analyser = context.createAnalyser();
//音声の音量を取得した要素分格納する変数
var frequencies = new Uint8Array(analyser.frequencyBinCount);
// 音量を表示するためのdiv要素を取得
var volume = document.getElementById(‘volume’);
var effect = document.getElementById(‘vol_effect’);
var loop;
 
//マイクの入力音声の振幅(音量)を取得する関数
var getFrequency=function(){
//周波数ごとの振幅を取得して配列に格納
analyser.getByteFrequencyData(frequencies);
return frequencies.reduce(function(previous,current){
return previous+current;
})/analyser.frequencyBinCount;
};
//端末のaudio(マイク)にアクセスする
navigator.mediaDevices.getUserMedia({audio: true})
.then(function(stream){
window.hackForMozzila=stream;
//音声の入力点(createMediaStreamSource)にマイク入力(stream)を設定し,
//出力点であるAnayserNodeオブジェクト(analyser)と接続(connect)させる。
context.createMediaStreamSource(stream).connect(analyser);
})
//マイクにアクセスできなかったorユーザーがマイクの利用を許可しなかった場合はエラーを表示
.catch(function(err) {
alert(err.message);
});
// 音量を取得して表示を更新
(loop = function() {
//マイクに入力されている音声の音量を取得、表示
volume = Math.floor(getFrequency());
volume.innerHTML=volume;
effect.style.width=volume+“%”;
requestAnimationFrame(loop);
})();
}
</script> 

<input type=“button” onclick="audio_input();" value=“マイクon”>

<!-- <!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Web Speech API</title>
<script>
window.SpeechRecognition = window.SpeechRecognition || webkitSpeechRecognition;
var recognition = new webkitSpeechRecognition();
recognition.lang = 'ja';
recognition.interimResults = true;
recognition.continuous = true;

let start = Date.now()
 
recognition.onsoundstart = function(){
  document.getElementById('status').innerHTML = "認識中";
  let end = Date.now();
  var elapsed = end - start; // ミリ秒単位の経過時間
  console.log(elapsed);
};
recognition.onnomatch = function(){
  document.getElementById('status').innerHTML = "もう一度試してください";
};
recognition.onerror= function(){
  document.getElementById('status').innerHTML = "エラー";
};
recognition.onsoundend = function(){
  document.getElementById('status').innerHTML = "停止中";
};
 
recognition.onresult = function(event){
    var results = event.results;
    console.log(event.timeStamp);
    for (var i = event.resultIndex; i<results.length; i++){
      if(results[i].isFinal)
        document.getElementById('result_text').innerHTML = results[i][0].transcript;
      else
        document.getElementById('result_text').innerHTML = "[途中経過] "+ results[i][0].transcript;
      console.log(results[i][0].transcript);
    }
}
</script> 
</head>
<body>
<textarea id="result_text" cols="100" rows="10">
</textarea>
<br>
<textarea id="status" cols="100" rows="1">
</textarea>
<br>
<input type="button" onClick="recognition.start();" value="音認開始">
</body>
</html> -->

<!-- <!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Web Speech API</title>
<script>
window.SpeechRecognition = window.SpeechRecognition || webkitSpeechRecognition;
var recognition = new webkitSpeechRecognition();
recognition.lang = 'ja';
 
recognition.onresult = function(event){
    var results = event.results;
    for (var i = event.resultIndex; i<results.length; i++)
        document.getElementById('result_text').innerHTML = results[i][0].transcript;
}
</script> 
</head>
<body>
<textarea id="result_text" cols="100" rows="10">
</textarea>
<br>
<input type="button" onClick="recognition.start();" value="音認開始">
</body>
</html> -->

<style>/*
<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8">
        <meta name="author" content="Human-Chrome Augmentation">
        <meta name="description" content="">
        <!-- <title>Human-Chrome Augmentation</title> -->
        <title>Reaction Subtitles</title>

        <link href="styles/style.css" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css2?family=Ubuntu&display=swap" rel="stylesheet">
        <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
    </head>

    <body>
        <header>
<!--             <h1>Human-Chrome Augmentation</h1> -->
            <h1>Reaction Subtitles</h1>
        </header>

<!--         <iframe class="slide" src="https://docs.google.com/presentation/d/e/2PACX-1vSTN_1rOZI-a8EZgR_78wvzmyQBWYOWtHIJFLF8jb9vLwTmR4-cPpiZBLEeEptUE59_8pOUsBNWGDZq/embed?start=false&loop=false&delayms=3000" frameborder="0" width="80%" height="839"></iframe> -->

        <div style="border:1px solid #000;">
            <div id="result_text"></div>
<!--           <form name="googleform" target="newtab" action="http://www.google.co.jp/search" method="GET" style="display:none;"> -->
            <form name="googleform" target="windowName" rel=“noopener noreferrer” action="http://www.google.co.jp/search" method="GET" style="display:none;">
                <input type="hidden" name="hl" value="ja">
                <input type="hidden" name="q" id="search_param" maxLength="255" size="30">
            </form>
            <input type="submit" id="start_recognition" value="search" style="color:#000; background-color:#ff9b00cf;">
        </div>
        <br>
        <div id="status">
            status: stop
        </div>
        <br>
        <div>
            <p>history<p>
                <ol id="history">
                </ol>
        </div>

        <script src="kuromoji.git/build/kuromoji.js"></script>

        <script type="text/javascript">
            window.open("https://www.google.com", "windowName", "resizable,scrollbars,status");
            
            var a = "";
            var speech_count = 0;
            
            var builder = kuromoji.builder({
                dicPath: "kuromoji.git/dict"
            });

            function buildkeitaiso(r) {
                console.log(r);
                console.log(typeof r);
                // kuromoji.builder({ dicPath: "kuromoji.js/dict" }).build(function (err, tokenizer) {
                builder.build(function(err, tokenizer){
                    var tokens = tokenizer.tokenize(r);
                    for (var item in tokens){
                        if (tokens[item]["pos"] == "名詞") {
                            // console.log(typeof tokens[item]["surface_form"]);
                            a += tokens[item]["surface_form"];
                            a += " ";
                            // console.log(typeof a);
                        }
                    }
                    a = a.slice(0, -1);
                    console.log(a);
                    console.log("a determined");
                    document.getElementById('search_param').setAttribute('value', a);
                    console.log("setAttribute");
                    document.googleform.submit();
                    console.log("submitted");
                    document.getElementById('status').innerHTML = "status: searched!";                
                    console.log("finish");

                    var textModMsg = document.getElementById("history");
                    var newElemLi = document.createElement("li");
                    var newElemLiText = document.createTextNode(r);
                    newElemLi.appendChild(newElemLiText);
                    textModMsg.appendChild(newElemLi);
                    // recognition.stop();
                    return;
                });
            }

            // function resolveAfterKeitaiso(q) {
            //     return new Promise(resolve => {
            //         buildkeitaiso(() => {
            //             resolve("resolved");
            //         }, q);
            //     });
            // }

            function resolveAfterKeitaiso(q) {
                return new Promise(resolve => {
                    buildkeitaiso(q);
                });
            }

            async function asyncCall(p) {
                await resolveAfterKeitaiso(p);
                // console.log(abc);

                // document.getElementById('search_param').setAttribute('value', a);
                // console.log("setAttribute");
                // document.googleform.submit();
                // console.log("submitted");
                // document.getElementById('status').innerHTML = "status: searched!";                
                // console.log("finish");
                // recognition.stop();
                // return;
                // expected output: "resolved"
            }

            document.getElementById("start_recognition").onclick = function vr_function() {

                a = "";
                var results = "";

                var result_text = document.getElementById('result_text');
                while (result_text.firstChild) {
                  result_text.removeChild(result_text.firstChild);
                }

                SpeechRecognition = webkitSpeechRecognition || SpeechRecognition;
                const recognition = new SpeechRecognition();
                recognition.lang = 'ja';

                // return progress
                recognition.interimResults = true;
                
                // continue recognition
                recognition.continuous = true;

                recognition.onresult = function(event) {
                    results = event.results;

                    if (document.getElementById('interim_result') == null) {
                        var interim = document.createElement('div');
                        // console.log(interim)
                        interim.setAttribute('class', 'results');
                        interim.setAttribute('id', 'interim_result');
                        document.getElementById('result_text').appendChild(interim);
                    }     

                    for (var i = event.resultIndex; i < results.length; i++) {
                        if (results[i].isFinal) {
                            speech_count++;
                            result_line = "<font size='4'>" + results[i][0].transcript + "</font>";
                            document.getElementById('interim_result').innerHTML = result_line;

                            document.getElementById('interim_result').setAttribute('id', 'result' + speech_count);
                            console.log(document.getElementById('interim_result'));
                            recognition.stop();

                            asyncCall(results[i][0].transcript);
                        }
                        // else {
                        //   document.getElementById('interim_result').innerHTML = "<font size='4' color='gray'>" + results[i][0].transcript + "</font>";
                        //   flag_speech = 1;
                        // }
                    }
                }
                document.getElementById('status').innerHTML = "status: recording...";
                recognition.start();
            }

        </script>

        <footer>
            <p>©Copyright 2021 Takuya Hara.</p>
        </footer>

    </body>
</html>
*/</style>